# Jira Scraper & Analytics + Bitbucket Commit Analyzer

Zestaw narzƒôdzi opartych na Pythonie do:
- **Jira Analyzer**: Scrapowanie danych projekt√≥w z Jira i generowanie kompleksowych raport√≥w HTML z interaktywnymi wizualizacjami i szczeg√≥≈ÇowƒÖ analizƒÖ przep≈Çywu zada≈Ñ
- **Bitbucket Analyzer**: Analiza statystyk commit√≥w i pull request√≥w z Bitbucket Server (On-Premise) dla zespo≈Ç√≥w deweloperskich

## Funkcje Jira Analyzer

- **Ekstrakcja Danych Projektu**: Scraping pe≈Çnej historii projektu z Jira wed≈Çug nazwy projektu
- **Analiza Przep≈Çywu Zada≈Ñ**: ≈öledzenie przej≈õƒá miƒôdzy statusami z interaktywnymi drilldown'ami
- **Trendy Czasowe**: Analiza metryk zada≈Ñ dzie≈Ñ po dniu lub tydzie≈Ñ po tygodniu miƒôdzy okre≈õlonymi datami
- **Interaktywne Wizualizacje**: Generowanie raport√≥w HTML z wykresami Plotly i NVD3.js
- **≈öledzenie B≈Çƒôd√≥w**: ‚≠ê Nowy wykres dziennego tworzenia i zamykania b≈Çƒôd√≥w z trendami
- **Postƒôp Test√≥w**: ‚≠ê Kumulatywny wykres wykonania test√≥w z podzia≈Çem na statusy (Passed/Failed/Executing)
- **Status Otwartych Zada≈Ñ**: ‚≠ê ≈öledzenie otwartych zada≈Ñ wed≈Çug kategorii (In Progress/Open/Blocked)
- **Kompleksowe Raporty**: Wiele typ√≥w wizualizacji z mo≈ºliwo≈õciƒÖ drilldown do konkretnych zada≈Ñ

## Instalacja

### Wymagania

- Python 3.13 lub wy≈ºszy
- Konto Jira z dostƒôpem do API
- Token API Jira

### Zale≈ºno≈õci

```bash
pip install -r requirements.txt
```

**requirements.txt:**
```
jira>=3.5.0
polars>=0.20.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.14.0
python-dateutil>=2.8.0
requests>=2.31.0
python-dotenv>=1.0.0
```

## Konfiguracja

### Zmienne ≈örodowiskowe

Narzƒôdzie obs≈Çuguje zar√≥wno **Jira Cloud** (API token) jak i **Jira On-Premise** (username/password).

#### Opcja 1: Jira Cloud (Atlassian)

Utw√≥rz plik `.env`:

```env
JIRA_URL=https://twoja-firma.atlassian.net
JIRA_EMAIL=twoj-email@firma.com
JIRA_API_TOKEN=twoj_token_api_tutaj
```

Wygeneruj token API:
1. Zaloguj siƒô na https://id.atlassian.com/manage/api-tokens
2. Kliknij "Create API token"
3. Skopiuj token i dodaj do pliku `.env`

#### Opcja 2: Jira On-Premise (Server/Data Center)

Utw√≥rz plik `.env`:

```env
JIRA_URL=http://jira.twoja-firma.com
JIRA_USERNAME=twoja_nazwa_uzytkownika
JIRA_PASSWORD=twoje_haslo
```

### Auto-detekcja

Narzƒôdzie automatycznie wykrywa metodƒô uwierzytelniania:
- Je≈õli ustawione sƒÖ `JIRA_EMAIL` i `JIRA_API_TOKEN` ‚Üí u≈ºywa API token (Cloud)
- Je≈õli ustawione sƒÖ `JIRA_USERNAME` i `JIRA_PASSWORD` ‚Üí u≈ºywa username/password (On-Premise)

**üìñ Zobacz [AUTHENTICATION_GUIDE.md](AUTHENTICATION_GUIDE.md) dla szczeg√≥≈Çowych instrukcji uwierzytelniania.**

## U≈ºycie

### Podstawowe U≈ºycie

```python
from jira_scraper import JiraScraper

# Inicjalizacja scrapera
scraper = JiraScraper()

# Wygeneruj raport dla projektu
scraper.generate_report(
    project_name="PROJ",
    start_date="2024-01-01",
    end_date="2024-10-23",
    output_file="jira_report.html"
)
```

### Interfejs Wiersza Polece≈Ñ

```bash
# Generowanie raportu z dziennymi trendami
python main.py --project PROJ --start-date 2024-01-01 --end-date 2024-10-23 --granularity daily

# Generowanie raportu z tygodniowymi trendami
python main.py --project PROJ --start-date 2024-01-01 --end-date 2024-10-23 --granularity weekly

# Okre≈õlenie w≈Çasnego pliku wyj≈õciowego
python main.py --project PROJ --start-date 2024-01-01 --end-date 2024-10-23 --output wlasny_raport.html

# Filtrowanie wykona≈Ñ test√≥w wed≈Çug etykiety
python main.py --project PROJ --start-date 2024-01-01 --end-date 2024-10-23 --test-label "Sprint-1"
```

### Zaawansowana Konfiguracja

```python
from jira_scraper import JiraScraper, ReportConfig

config = ReportConfig(
    granularity="daily",  # lub "weekly"
    include_changelog=True,
    track_custom_fields=["Story Points", "Sprint"],
    status_categories={
        "in_progress": ["In Progress", "In Development"],
        "testing": ["To Test", "In Testing", "QA"],
        "blocked": ["Blocked", "On Hold"],
        "done": ["Done", "Closed", "Resolved"]
    }
)

scraper = JiraScraper(config=config)
scraper.generate_report(
    project_name="PROJ",
    start_date="2024-01-01",
    end_date="2024-10-23"
)
```

## Funkcje Raportu

### 1. Nowe Wykresy (‚≠ê Najnowsze Funkcje)

#### ≈öledzenie B≈Çƒôd√≥w
- Dzienne wykresy s≈Çupkowe tworzenia vs zamykania b≈Çƒôd√≥w
- Linie trend√≥w dla obu metryk
- Interaktywny drilldown pokazujƒÖcy szczeg√≥≈Çy b≈Çƒôd√≥w wed≈Çug daty
- Statystyki podsumowujƒÖce (ca≈Çkowita, ≈õrednia, obecnie otwarte)

#### Postƒôp Wykonania Test√≥w
- Kumulatywny wykres warstwowy pokazujƒÖcy postƒôp test√≥w w czasie
- Podzia≈Ç status√≥w: Passed, Failed, Executing, To Do, Aborted
- Filtrowanie wed≈Çug etykiety (np. "Sprint-1")
- Procent pokrycia testami
- Drilldown z linkami do wykona≈Ñ test√≥w

#### Status Otwartych Zada≈Ñ
- Wykres warstwowy otwartych zada≈Ñ wed≈Çug kategorii statusu
- Kategorie: In Progress, Open, Blocked
- Linia trendu dla ca≈Çkowitej liczby otwartych zada≈Ñ
- Statystyki (≈õrednia, maksimum, obecnie otwarte)

**üìñ Zobacz [NEW_CHARTS_DOCUMENTATION.md](NEW_CHARTS_DOCUMENTATION.md) dla szczeg√≥≈Çowej dokumentacji nowych wykres√≥w.**

### 2. Analiza Przep≈Çywu Zada≈Ñ

Scraper ≈õledzi ka≈ºde przej≈õcie statusu dla ka≈ºdego zadania i dostarcza:

- **Diagramy Przep≈Çywu**: Wizualna reprezentacja przemieszczania siƒô zada≈Ñ miƒôdzy statusami
- **Wska≈∫nik Odbiƒá**: Procent zada≈Ñ, kt√≥re wr√≥ci≈Çy do poprzednich status√≥w
- **≈öredni Czas w Statusie**: Czas spƒôdzany przez zadania w ka≈ºdym statusie
- **Wsp√≥lne Wzorce**: Identyfikacja czƒôsto wystƒôpujƒÖcych ≈õcie≈ºek przej≈õƒá miƒôdzy statusami
- **Interaktywny Drilldown**: Klikniƒôcie na wzorzec pokazuje listƒô zada≈Ñ z linkami do Jira

Przyk≈Çadowe metryki:
- W Trakcie ‚Üí Do Test√≥w ‚Üí W Trakcie (liczba regresji)
- Do Test√≥w ‚Üí Gotowe (pomy≈õlny przep≈Çyw)
- ≈örednia liczba dni od utworzenia do zako≈Ñczenia

### 3. Trendy Czasowe

#### Granulacja Dzienna
- Zadania utworzone dziennie
- Zadania zako≈Ñczone dziennie
- Dystrybucja status√≥w w czasie
- Trendy prƒôdko≈õci

#### Granulacja Tygodniowa
- Metryki zagregowane tygodniowo
- Analiza na poziomie sprintu (je≈õli dotyczy)
- Por√≥wnania tydzie≈Ñ do tygodnia

### 4. Wizualizacje

Raport HTML zawiera:

#### Interaktywne Wykresy NVD3.js
- **Wykresy Liniowe**: Kumulatywne trendy zada≈Ñ w czasie
- **Wykresy Warstwowe**: Ewolucja dystrybucji status√≥w
- **Wykresy S≈Çupkowe**: Tworzenie/uko≈Ñczenie zada≈Ñ wed≈Çug okresu
- **Wykresy Wielos≈Çupkowe**: Analiza por√≥wnawcza miƒôdzy okresami

#### Statyczne Wykresy Seaborn
- **Mapy Ciep≈Ça**: Macierz czƒôstotliwo≈õci przej≈õƒá miƒôdzy statusami
- **Wykresy Pude≈Çkowe**: Dystrybucja czasu w statusie
- **Wykresy Rozk≈Çadu**: Analiza czasu uko≈Ñczenia zada≈Ñ
- **Macierze Korelacji**: Zale≈ºno≈õci miƒôdzy r√≥≈ºnymi metrykami

### 5. Kompleksowe Metryki

- **Przepustowo≈õƒá**: Zadania uko≈Ñczone na okres
- **Czas Cyklu**: Czas od rozpoczƒôcia do zako≈Ñczenia
- **Czas Realizacji**: Czas od utworzenia do zako≈Ñczenia
- **Praca w Toku (WIP)**: Liczba aktywnych zada≈Ñ w czasie
- **Czƒôstotliwo≈õƒá Zmian Statusu**: Liczba przej≈õƒá na zadanie
- **Analiza Regresji**: Zadania cofajƒÖce siƒô w przep≈Çywie pracy

## Struktura Projektu

```
jira-scraper/
‚îÇ
‚îú‚îÄ‚îÄ main.py                 # Punkt wej≈õcia CLI
‚îú‚îÄ‚îÄ jira_scraper/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py         # Podstawowa interakcja z API Jira
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py        # Analiza danych i kalkulacja metryk
‚îÇ   ‚îú‚îÄ‚îÄ visualizer.py      # Generowanie wykres√≥w (NVD3 + Seaborn)
‚îÇ   ‚îú‚îÄ‚îÄ report_generator.py # Kompilacja raportu HTML
‚îÇ   ‚îî‚îÄ‚îÄ models.py          # Modele danych i struktury
‚îÇ
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ report_template.html  # Szablon HTML dla raport√≥w
‚îÇ
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles.css     # Stylowanie raportu
‚îÇ   ‚îî‚îÄ‚îÄ js/
‚îÇ       ‚îî‚îÄ‚îÄ nvd3/          # Pliki biblioteki NVD3.js
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_scraper.py
‚îÇ   ‚îú‚îÄ‚îÄ test_analyzer.py
‚îÇ   ‚îî‚îÄ‚îÄ test_visualizer.py
‚îÇ
‚îú‚îÄ‚îÄ .env                   # Zmienne ≈õrodowiskowe (nie w git)
‚îú‚îÄ‚îÄ .env.example          # Przyk≈Çadowy plik ≈õrodowiskowy
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## Przyk≈Çadowe Wyj≈õcie

Wygenerowany raport HTML zawiera nastƒôpujƒÖce sekcje:

### 1. Podsumowanie Wykonawcze
- Ca≈Çkowita liczba przeanalizowanych zada≈Ñ
- Zakres dat
- Prƒôdko≈õƒá projektu
- PrzeglƒÖd kluczowych metryk

### 2. Analiza Przep≈Çywu Zada≈Ñ
- Diagram Sankeya przej≈õƒá miƒôdzy statusami
- Najczƒôstsze wzorce przep≈Çywu
- Statystyki regresji

### 3. Trendy Czasowe
- Interaktywne wykresy szereg√≥w czasowych
- Dystrybucja status√≥w w czasie
- Trendy tworzenia vs uko≈Ñczenia

### 4. Analiza Status√≥w
- Czas spƒôdzony w ka≈ºdym statusie
- Czƒôstotliwo≈õƒá zmian statusu
- Analiza zablokowanych zada≈Ñ

### 5. Szczeg√≥≈Çowe Tabele
- Historia poszczeg√≥lnych zada≈Ñ
- Log przej≈õƒá miƒôdzy statusami
- Identyfikacja warto≈õci odstajƒÖcych

## Limitowanie Szybko≈õci API

API Jira ma limity szybko≈õci. Scraper zawiera:
- Automatyczne wykrywanie limit√≥w szybko≈õci
- Logikƒô ponownych pr√≥b z wyk≈Çadniczym cofaniem
- Wska≈∫niki postƒôpu dla d≈Çugotrwa≈Çych operacji

```python
# Konfiguracja limitowania szybko≈õci
scraper = JiraScraper(
    max_retries=3,
    backoff_factor=2,
    requests_per_minute=60
)
```

## Prywatno≈õƒá Danych

- Wszystkie dane sƒÖ przetwarzane lokalnie
- ≈ªadne dane nie sƒÖ wysy≈Çane do us≈Çug zewnƒôtrznych
- Dane uwierzytelniajƒÖce API sƒÖ przechowywane bezpiecznie w pliku `.env`
- Dodaj `.env` do `.gitignore` aby zapobiec eksponowaniu danych uwierzytelniajƒÖcych

## RozwiƒÖzywanie Problem√≥w

### Problemy z Uwierzytelnianiem
```
Error: 401 Unauthorized
```
- Sprawd≈∫ poprawno≈õƒá tokena API
- Upewnij siƒô, ≈ºe email Jira pasuje do w≈Ça≈õciciela tokena
- Sprawd≈∫, czy token ma wymagane uprawnienia

### Projekt Nie Znaleziony
```
Error: Project 'PROJ' not found
```
- Sprawd≈∫ poprawno≈õƒá klucza projektu (uwzglƒôdnia wielko≈õƒá liter)
- Upewnij siƒô, ≈ºe masz dostƒôp do projektu
- Sprawd≈∫ uprawnienia projektu w Jira

### Problemy z PamiƒôciƒÖ dla Du≈ºych Projekt√≥w
Dla projekt√≥w z tysiƒÖcami zada≈Ñ:
```python
# Przetwarzanie partiami
scraper.generate_report(
    project_name="PROJ",
    start_date="2024-01-01",
    end_date="2024-10-23",
    batch_size=100  # Przetwarzaj po 100 zada≈Ñ na raz
)
```

## Optymalizacja Wydajno≈õci

- **Cachowanie**: Wyniki sƒÖ cachowane, aby uniknƒÖƒá nadmiarowych wywo≈Ça≈Ñ API
- **Przetwarzanie R√≥wnoleg≈Çe**: U≈ºywa wƒÖtk√≥w dla wsp√≥≈Çbie≈ºnych zapyta≈Ñ API
- **Aktualizacje Przyrostowe**: Aktualizuj istniejƒÖce raporty bez pe≈Çnego ponownego scrapowania

```python
# W≈ÇƒÖcz cachowanie
scraper = JiraScraper(cache_enabled=True, cache_ttl=3600)

# U≈ºyj istniejƒÖcego cache
scraper.generate_report(
    project_name="PROJ",
    start_date="2024-01-01",
    end_date="2024-10-23",
    use_cache=True
)
```

## Wsp√≥≈Çpraca

Wk≈Çad mile widziany! Proszƒô:

1. Zforkuj repozytorium
2. Utw√≥rz ga≈ÇƒÖ≈∫ funkcji (`git checkout -b feature/niesamowita-funkcja`)
3. Zatwierd≈∫ zmiany (`git commit -m 'Dodaj niesamowitƒÖ funkcjƒô'`)
4. Wypchnij do ga≈Çƒôzi (`git push origin feature/niesamowita-funkcja`)
5. Otw√≥rz Pull Request

## Testowanie

Uruchom pakiet test√≥w:

```bash
# Uruchom wszystkie testy
pytest

# Uruchom z pokryciem
pytest --cov=jira_scraper tests/

# Uruchom konkretny plik testowy
pytest tests/test_scraper.py
```

---

## üìä Bitbucket Commit Analyzer

Narzƒôdzie do analizy statystyk commit√≥w i pull request√≥w z Bitbucket Server (On-Premise).

### Funkcje Bitbucket Analyzer

- üìä Analiza commit√≥w dla wybranych u≈ºytkownik√≥w
- üìà Statystyki linii kodu: dodane, usuniƒôte, zmienione (osobno)
- üèÜ Rankingi Top 3 i Bottom 3 wed≈Çug:
  - Liczby commit√≥w
  - Liczby zmian (linie kodu)
  - Liczby pull request√≥w
- üë• Wsparcie dla alias√≥w u≈ºytkownik√≥w (grupowanie zespo≈Çowe)
- üìÖ Filtrowanie wed≈Çug zakresu dat
- üíæ Cachowanie danych dla szybszego przetwarzania
- üìÑ Generowanie raport√≥w HTML z kolorystycznymi wizualizacjami

### Konfiguracja Bitbucket

Dodaj do pliku `.env`:

```env
# Bitbucket Server (On-Premise)
BITBUCKET_URL=http://bitbucket.your-company.com
BITBUCKET_USERNAME=your_username
BITBUCKET_PASSWORD=your_password_or_api_token
```

### U≈ºycie Bitbucket Analyzer

#### Podstawowe u≈ºycie

```bash
python bitbucket_main.py --project PROJ --repository my-repo \
    --authors john.doe jane.smith
```

#### Z zakresem dat

```bash
python bitbucket_main.py --project PROJ --repository my-repo \
    --authors john.doe jane.smith bob.wilson \
    --start-date 2024-01-01 --end-date 2024-12-31
```

#### Z aliasami u≈ºytkownik√≥w (grupowanie zespo≈Çowe)

```bash
python bitbucket_main.py --project PROJ --repository my-repo \
    --authors john.doe jane.smith bob.wilson alice.jones \
    --aliases "Team A:john.doe,jane.smith" "Team B:bob.wilson,alice.jones" \
    --start-date 2024-01-01
```

#### Ze szczeg√≥≈ÇowƒÖ listƒÖ commit√≥w

```bash
python bitbucket_main.py --project PROJ --repository my-repo \
    --authors john.doe \
    --detailed-commits \
    --output john_commits_report.html
```

### Jak Dzia≈Ça Liczenie Linii?

- **Linie dodane**: Nowe linie dodane do kodu
- **Linie usuniƒôte**: Linie usuniƒôte z kodu
- **Linie zmodyfikowane**: Linie zmienione (nie liczone jako dodane + usuniƒôte)
- **Suma zmian**: Dodane + Usuniƒôte + Zmodyfikowane

> **Uwaga**: Linie zmodyfikowane sƒÖ liczone oddzielnie. Je≈õli linia zosta≈Ça zmieniona,
> jest liczona jako "zmodyfikowana", a nie jako "usuniƒôta + dodana".

### Raport Bitbucket

Wygenerowany raport HTML zawiera:

1. **Podsumowanie statystyk** - ca≈Çkowite liczby dla wszystkich u≈ºytkownik√≥w
2. **Rankingi Top 3 i Bottom 3** - wed≈Çug commit√≥w, zmian i PR√≥w
3. **Szczeg√≥≈Çowa tabela u≈ºytkownik√≥w** - pe≈Çne statystyki dla ka≈ºdego developera
4. **Szczeg√≥≈Çowe listy commit√≥w** (opcjonalnie) - dla ka≈ºdego u≈ºytkownika

üìñ **Pe≈Çna dokumentacja**: [bitbucket_analyzer/README.md](bitbucket_analyzer/README.md)

---

## Licencja

Licencja MIT - szczeg√≥≈Çy w pliku LICENSE

## Podziƒôkowania

- [Jira Python Library](https://jira.readthedocs.io/)
- [NVD3.js](http://nvd3.org/) za interaktywne wizualizacje
- [Seaborn](https://seaborn.pydata.org/) za wizualizacje statystyczne

## Wsparcie

W przypadku problem√≥w, pyta≈Ñ lub wsp√≥≈Çpracy:
- Otw√≥rz zg≈Çoszenie na GitHubie
- Sprawd≈∫ [Wiki](https://github.com/yourrepo/jira-scraper/wiki) dla szczeg√≥≈Çowej dokumentacji
- Przejrzyj istniejƒÖce zg≈Çoszenia przed utworzeniem nowych

## Plan Rozwoju

- [ ] Dodaj wsparcie dla Jira Cloud i Jira Server
- [ ] Zaimplementuj analizƒô niestandardowych p√≥l
- [ ] Dodaj eksport do formatu PDF
- [ ] Utw√≥rz widok pulpitu z aktualizacjami w czasie rzeczywistym
- [ ] Dodaj analizƒô predykcyjnƒÖ czasu uko≈Ñczenia
- [ ] Wsparcie dla wielu projekt√≥w w jednym raporcie
- [ ] Integracja ze Slack/Teams dla automatycznego raportowania

## Historia Zmian

### Wersja 1.0.0 (Aktualna)
- Pierwsze wydanie
- Podstawowa funkcjonalno≈õƒá scrapowania projektu
- Generowanie raportu HTML z NVD3 i Seaborn
- Analiza przep≈Çywu zada≈Ñ
- Analiza trend√≥w dziennych i tygodniowych
- ≈öledzenie przej≈õƒá miƒôdzy statusami
